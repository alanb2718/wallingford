\documentclass{article}
\setlength{\topmargin}{-0.25 in}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8.5 in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\parindent}{0.0in}
\setlength{\parskip}{7pt plus 1pt}

\usepackage{url}

\sloppy

\begin{document}

\title{Toward a Constraint Reactive Programming Language: \\ 
 Additional Details} 

\author{Alan Borning} \date{\today}

\maketitle

\section{Introduction}

This note includes additional details and ideas yet to be worked out
to accompany the workshop paper ``Wallingford: Toward a Constraint
Reactive Programming Language.''

discuss complexities of the standard model: signals, lifting, etc; and how
this model avoids them

\section{Advancing Time in Wallingford}
\label{sec:advancing-time}

The workshop paper includes a description of how the
\verb|advance-time| method handles the case of a \verb|when| or
\verb|while| temporal constraint.

\begin{quotation}
If a reactive thing includes \verb|when| or \verb|while| temporal
constraints, handling the \verb|advance-time| message is more complex,
since a \verb|when| or \verb|while| condition might be true at some
time between its current time and the new proposed time.  Even in the
current implementation, in which time is represented as an integer, it
would be quite inefficient to methodically advance time 1 millisecond
per tick, checking each tick for conditions that have become true; and
impossible when the implementation is rewritten to use real-valued
time.  Instead, the system uses its constraint solving capabilities to
find the next time to which to advance.  Let the reactive thing's
current time be $r$, and the new proposed time be $t$\@.  The system
then solves for a time $s$ such that $r<s<t$, all of the required
constraints hold, and at least one condition in a \verb|when| or
\verb|while| statement holds.  If no such time exists, the reactive
thing can safely advance its time to $t$\@.  But if such a time $s$
does exist, the system uses iterative deepening to find the minimum
such time $s_{\min}$, and the thing advances its clock to $s_{\min}$.
It then uses \verb|wally-solve| to solve the constraints at $s_{\min}$
(including the soft constraints), asserts the constraints in the
bodies of all \verb|when| or \verb|while| statements whose condition
holds at $s_{\min}$ (for a \verb|when|, just at that instant, and for
a \verb|while|, as long as the condition holds --- like a bounded
version of \verb|always|), and finally calls \verb|wally-solve| again.
Finally, if there were such a time $s_{\min}<t$, the reactive thing
calls \verb|advance-time| again to attempt to advance its time to $t$\@.
(It might need to advance to multiple intermediate times before
eventually getting to $t$.)
\end{quotation}

There are some subtle issues with this, which this section attempts to
record.  Eventually, both the algorithm description and the
specification should be made more precise, and there should be an
actual proof of correctness, or at least a less hand-wavy argument.

An informal specification for \verb|advance-time| is as follows. 

\begin{quotation}
Let the reactive thing's current time be $r$, and let the proposed new
time be $t$ (supplied as an argument to the \verb|advance-time|
method).  If there exists a time $s$ such that $r<s<t$, and such that
at least one of the conditions in a \verb|when| or \verb|while|
statement is true at time $s$ given a correct solution to all the hard
and soft constraints active at $s$, then we can't advance time to $t$\@.
Instead, find the minimum such time $s_{\rm spec}$, advance time to
$s_{\rm spec}$, add all the assertions from the \verb|when| and
\verb|while| temporal constraints whose conditions are satisfied,
resatisfy the constraints, and try to advance time again to $t$.  If
there does not exist such a time $s$, then just advance time to $t$.
\end{quotation}

There are some subtle differences between this informal specification
and the algorithm --- in particular the spec refers to the solution to
all of the constraints (hard and soft), whereas the algorithm first
just solves the hard constraints, and in the spec the \verb|when| and
\verb|while| conditions are read-only with respect to finding a
solution to the constraints, whereas in the algorithm they are used in
finding the solution.  Nevertheless I believe the algorithm finds a
time $s_{\min}$ that is less than or equal to the correct value
$s_{\rm spec}$.  If $s_{\min} = s_{\rm spec}$, clearly things are
OK\@.  If $s_{\min} < s_{\rm spec}$, no harm is done: we advance time
to $s_{\min}$, check the conditions on the \verb|when| and
\verb|while| statements, find none of them hold, and try to advance
time again.  As long as we advance by some finite amount each step,
this will eventually hit $s_{\rm spec}$ (and in fact in all but some
very strange cases, we seem to hit $s_{\min} = s_{\rm spec}$
immediately).

The algorithm would be incorrect if we could have $s_{\min} > s_{\rm spec}$,
since then we could skip over a \verb|when| and \verb|while| that
should have been activated, but I believe this can never happen.
Suppose to the contrary the algorithm finds $s_{\min} > s_{\rm spec}$.  
$s_{\rm spec}$ must be such that one of the \verb|when| or
\verb|while| conditions holds for the solution to all of the hard and
soft constraints.  All of the required constraints must hold in this
solution, and at least one of the \verb|when| or \verb|while|
conditions, meaning that the constraint solver must have found an
incorrect solution.  But we assume that the solver is sound (although
probably incomplete), hence this can't happen.

\subsection{False Positives}
\label{sec:false-positives}

We can in fact have false positives in the sense of checking times
unnecessarily, in other words solutions for which 
$s_{\min} < s_{\rm spec}$.  As a first example consider:

\begin{verbatim}
  weak b=(seconds)
  when b=100
    [assert stuff]
\end{verbatim}

Suppose the current time $r$ is 20.  If we try to advance to $t=50$,
the required constraints are just $20<s<50$ and $b=100$.  This clearly
has a solution, for example $s=40$ and $b=100$.  In the current
implementation using integers for time, $s_{\min}$ will be 21.  So we
advance time from 20 to 21, but this is a false positive, since when
we call \verb|wally-solve| and solve the whole set of constraints,
including the weak constraint, we get $b=21$, so the \verb|when|
condition does not hold.  Then we try advancing time again and get
$s_{\min}=22$.  We keep on going until it is 49, and then we advance
to 50 and are done.  (The \verb|when| never actually gets activated.)
This is weird, but the constraints are also weird and we do get a
correct answer, so this is not a disaster.

When we use real numbers for time and try to find $s_{\min}$, the
solver should say that the constraints in conjunction with the
minimization constraint are unsolvable.  (For any $s_{\min}>20$, say
$s_{\min}=20.01$, we can always find a smaller $s_{\min}$.)  This
still seems OK --- this is after all a pathological case.

Here is a second example, also somewhat pathological.  The algorithm
nevertheless still works on it for both integral and real time.

\begin{verbatim}
  required b <= (seconds)
  weak  b = (seconds)-5
  when b=100
    [assert stuff]
\end{verbatim}

First let's try integral time.  Suppose the current time $r$ is 20 and
we try to advance to $t=200$.  Then the required constraints fed to
the algorithm are $20<s<200$, $b \leq s$, and $b=100$.  Here $b \leq
s$ is is the translation of \verb|required b <= (seconds)|.  This has
the solution $s_{\min}=100$, $b=100$.  But we now solve all of the
constraints, including the weak constraint \verb|b = (seconds)-5| but
not the \verb|when| condition.  We now get $b=95$ and the \verb|when|
condition is not satisfied.

This is ok so far; we advance time to the false positive of 100 and
then try again to advance it to 200.  Now the required constraints fed
to the algorithm are $100<s<200$, $b \leq s$, and $b=100$.  This has
the solution $s_{\min}=101$ and $b=100$. Then
solving all of the constraints, including the weak one but not the
\verb|when| condition, we get $b=96$ and again the \verb|when|
condition is not satisfied.

So we advance time again to the false positive of 101 and try again to
advance it to 200.  Repeating the above, now the required constraints fed
to the algorithm are $101<s<200$, $b \leq s$, and $b=100$.  This has
the solution $s_{\min}=102$ and $b=100$. Then
solving all of the constraints, including the weak one but not the
\verb|when| condition, we get $b=97$ and again the \verb|when|
condition is not satisfied.

We keep doing this until we get to $s_{\min}=105$ and $b=100$.
Finally, the \verb|when| condition is satisfied.  We add its
assertions, and try yet again to advance time to 200.  Assuming the
assertions in the \verb|when| don't have anything to do with $b$, this
last time we can just advance time to 200 and we are done.

For real-valued time, the problem becomes too hard for the solver.  On
the first iteration we have the same behavior as above and find
$s_{\min}=100$.  So we we advance time to the false positive of 100
and then try again to advance it to 200.  Now the required constraints
fed to the algorithm are $100<s<200$, $b \leq s$, and $b=100$.  This
has no minimum value for $s$, and so the system should just say the
constraints are too hard and give up.  This is slightly annoying,
since in fact a correct solution would be to advance time to 105,
satisfy the assertions in the \verb|when|, and then advance to 200.
But since the algorithm doesn't give a wrong answer, and the
constraints are on the pathological side anyway, again this is not a
disaster.

Another set of pathological cases can be generated by considering
\verb|when| conditions that don't have any connection to time.  This
doesn't seem to introduce any additional problems however.  If the
condition is inherently unsatisfiable, it is ignored, if it can be
satisfied by some other values of the variables, for integral time, we
just advance time by 1 each iteration, while for real-valued time we
would get an unsatisfiable set of constraints (since time could be
advanced by some infinitesimal amount).

\subsection{Infinite Searches for Advancing Time}

The above examples show cases of false positives using integral time,
but for which the algorithm can still find a solution.  We also have
cases of false positives using real-valued time with constraints that
are too hard for the solver; I'm not sure whether there are cases of a
false positive using real-valued time that can still be solved using
the algorithm.

Can we ever have an infinite search while trying to advance time?  For
integral time, clearly not, since since time is advanced by at least 1
each iteration.  I'm not sure for real-valued time.  We're not going
to try to advance time on each iteration by some infinitesimal amount
--- in such a case, the solver will say that the minimization
constraint has not solution or that the constraints are otherwise too
hard.  However, there might be a pathological case involving a Zeno's
paradox type search, in which time is advanced for example by 1.0,
then 0.5, then 0.25, and so forth.

\subsection{while Constraints}

The algorithm needs to be fixed for while constraints --- the
test is that a while condition flips sign, not just that it is true.
So if it is false at the current time, then the algorithm is the same;
but if it's true at the current time, then we look for a time that it
becomes false.

\subsection{An Algorithm that Doesn't Work}

The above algorithm first finds a minimum time $s$, and then considers
the soft constraints.  What if we try combining this, so that the
condition for continuing the search is either that the time decreases
\emph{or} the penalty for the soft constraints decreases?  This
doesn't work --- we need to find the minimim time, and then solve the
soft constraints.  If we try to combine the search, we might find a
value for the soft constraint penalty that locks us in to solutions
that don't have the minimum time.  Here is an example.

\begin{verbatim}
  x := 10;
  when (seconds)=50 and x=20
    [assert stuff]
  when (seconds)=100 and x=10
    [assert other stuff]
\end{verbatim}

Suppose we are trying to advance time to 200.  If we happen to
minimize time first, and find $s=50$, this works; but if we minimize
the penalty for the stay on $x$ first, we end up with $s=100$, which
is not the minimum.

\section{Push and Pull}

This section (for the moment) outlines changes to the code to deal with
push as well as pull updates for viewing.

Semantics: just pull.  Push is an optimization, and also lets the view be
updated more quickly if something changed.  If you aren't looking at
something, its time doesn't advance and no error conditions would occur
that might otherwise occur if its time did advance.

rename 'change' to 'sampling'.  options are
pull
push 
push\&pull
none

If the thing is static, sampling should be none.  Or it could be
push, and no sampling are ever sent.

How thing determines 'sampling'
 - if there are 'always' constraints that involve time (seconds or
   milliseconds) then sampling includes pull
 - if there are 'when' constraints sampling includes push

That's it!  Could optionally remove push if there is a pull, but let's
leave it, and leave it to the viewer to decide what to do with a push.

The viewer can treat these as heuristic.  For example, if sampling
is push\&pull, it might ignore push updates if it is updating on a
smooth schedule and doesn't want to disrupt the visual flow.

\subsection{Changes to Viewer}

DONE Add a thing-changed message, which just does a show (the thing should
already have advanced its time appropriately).

for demo: add a second viewer. \\
unwatch - should also clear display in all cases (misses first time)

\subsection{Changes to reactive-thing}

have a list of viewers
unwatch - remove viewer from list

viewed-by message -- add viewer to list  and tell it the sampling type

refactor advance-time-helper to have a separate find-time function.  This
finds the next time t to advance to such that a when condition might be
true then.

have a set-alert message -- this calls find-time.  If there is such a time
t, it checks if there is an existing alert.  If there is, it terminates
that alert's thread.  In any case it sets up a new thread that tells the
thing to wake up at t and advance time to then.  When it wakes up it
advances time, and then calls find-time again.

call find-time when the thing is first watched (that is, when the list of
watchers changes from '() to not null), and also whenever there is a new
LBP.


If there are push notifications, find the next time t to advance to at the
time the thing is created, set up a thread to sleep until then, and then
advance time to t.  To do this, we could call advance-time to say a week
from now.  If we don't find any times, don't do anything; otherwise set up
the thread.

Slight uncleanliness: for 32 bits we could advance 49 days at most (or
maybe 1/2 of that).  Let's advance a week for now.  If we have real valued
times, maybe we could advance to infinity, assuming that is represented.

If there are LBP tests in when conditions, whenever a button press event
arrives, re-solve for the next time to advance to (which might be right
then, but might be in the future instead).  NB: we can never turn the clock
back!

should reactive thing tell the viewer it's interested in button events?
Could ignore this for now; eventually it seems more elegant to say that
it's listening for them, and the viewer only sends them if the thing cares.


interesting: a when with a condition ``do this 5 seconds before the button
is pressed''






\section{Other}

do code cleanup -- can we reduce some of the use of threads and blocking?
What about all the ordinary messages that redirect to the thread?  Can
there be a replacement for 'send' that just does this?  (Maybe a macro?)
what about inheritance?

refactor viewer -- time set in several places etc

opening two viewers on a thing should work

unit tests for viewer?  maybe have a stub drawing context?

invariant: left-button-press event always arrives at or after the thing's
current time

is there any relation between the thing's current time $s$ and actual time $t$?
For example we might have always $s \leq t$ -- but not sure this is needed.

\section{Previous and Next}

The CROW paper includes an example using the \verb|(previous expr)|
construct, which denotes the value of \verb|expr| at some time $p$ less
than the current time and greater than any other time that the thing's
state has been accessed.  \verb|previous| can only be used in a \verb|when|
constraint --- it doesn't make sense in a \verb|while|.  However, there
could be more than one use of \verb|previous| in the \verb|when|, and also
additional \verb|when| constraints whose condition matches the current
time.  In this situation \emph{all} occurrences of \verb|previous| denote
the same time, allowing their effects to be combined.  

After all of the bodies of the whens are satisfied, the truth value of all
of the whens should not have changed; it is an error if one of them did
change.  This isn't currently checked but would be straightforward to add.
This avoids pathological cases in which, for example, a when body causes
another when to become active at the same instant, resulting in a cascade
of whens; or if satisfying the body causes the condition of that when to
become false.  If the programmer does want this sort of cascade, use
\verb|next| instead, described below.

We should also have an analogous \verb|(next expr)| construct, which
denotes the value of \verb|expr| at some time $q$ greater than the current
time and less than any other time that the thing's state will be accessed.

Using \verb|next| we can closely simulate imperative code using a variable
representing the program counter.  (This is definitely \emph{not} how
Wallingford applications are likely to be written; this is just noted to
show that the reactive framework is expressive enough to encompass that
style.)

\begin{verbatim}
(when (zero? (millisecods))
  (equal? pc 0)
  (equal? (next pc) (+ 1 pc)))

(when (equal? pc 1)
  [assert stuff]
  (equal? (next pc) (+ 1 pc)))

....
\end{verbatim}

\verb|next| can be defined as a procedure, as follows.  \verb|(next expr)|
returns a fresh variable \verb|v| of the appropriate type (based on the
current type of expr).  Also record this information.  Satisfy the
constraints, which will involve finding a value for each \verb|v| (there
may be more than one \verb|next|).  Then solve again for
\verb|(equal? expr (evaluate v))|.  If \verb|expr| is one of Rosette's
types, e.g., number?, then \verb|n| is a symbolic variable of that type.
Otherwise we need to make a new shell structure or object, with variables
at the leaves, and set \verb|n| to that.  This is kind of complicated, so
it is probably easiest to start with just primitives for this.

Another approach (also complicated): rewrite any constraints involving
\verb|next| to use \verb|previous| instead (or actually just
\verb|evaluate|).  Recursive function \verb|prevify| takes an s-expression
and returns a new s-expression with \verb|(next expr)| replaced by
\verb|expr|, and everything else not involving \verb|next| replaced by
\verb|(evaluate expr)|.  Outline of \verb|(prevify expr)|: if \verb|expr|
is a pair \verb|(next expr)|, return \verb|expr|.  If \verb|expr| is a pair
that doesn't contain \verb|next|, then return \verb|(evaluate expr)|.  If
\verb|expr| is a pair that contains \verb|next|, return a new list
consisting of \verb|prevify| of each other element.  If \verb|expr| is a
symbolic variable, return \verb|(evaluate expr)|.  Otherwise just return
\verb|expr|.  Then solve all the conditions etc but not the bodies with
\verb|next|.  Then solve again using the prevified bodies.

Discussion of hybrid automata.  The previous/next version seems to
fit better with constraints.  If we have two \verb|when| constraints
whose conditions hold at the same instant, the semantics of previous
are clear: just throw in all the constraints.  If we use the hybrid
automata approach, which one gets executed first?  It could be
arbitrary but this still doesn't seem as clean.

chains of actions -- might have some additional syntax to support that

\section{Non-Determinacy}

if there are multiple solutions to the constraints, might hit a when
condition with one solution and not the other.  that's just the way it is.
Might imagine a tool to detect the possibility of multiple solutions and
warn the programmer, but I would not want to forbid them.

\section{Wallingford as an Observer Language}

The following paragraph attempts to give an intuition for what it means for
Wallingford to have ``pull'' semantics.  Suppose that the current time for
a reactive thing is $r$\@.  Until we ask to advance time, we don't whether
there are any errors in advancing time beyond $r$.  When we do ask to
advance time --- say to $t$ --- intuitively the thing's clock advances
smoothly through all times between $r$ and $t$.  If there are any
\verb|when| constraints whose conditions become true at any instant between
$r$ and $t$, we satisfy those assertions at that intermediate time, as
described in Section \ref{sec:advancing-time}.  In addition, if the system
would encounter an exception sometime between $r$ and $t$, we should raise
it.  However, we don't care (yet) what happens beyond time $t$\@.

A direction for formalizing ``the thing's clock advances smoothly through
all times between $r$ and $t$'' could be to say that if we advanced time to
\emph{any} additional point in time between $r$ and $t$, the result when we
get to $t$ would still be the same.

For example, suppse that a reactive thing includes the following constraint:
\begin{verbatim}
  always x=1/(seconds-40)
\end{verbatim}

If the time is currently 0 and we advance to 50, we should still raise the
divide-by-zero exception, since if we did advance time to 40, which is
between 0 and 50, we would hit the problem.  On the other hand, just
advancing time to 30 would not encounter the exception.

TODO: add description of when to push, when to pull

relation of this to lazy evaluation, Fran and Haskell, etc

relation to observer languages; cite Alan Kay papers (Scientific American
article, other paper)



\end{document}
