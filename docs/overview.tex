\documentclass{article}
\setlength{\topmargin}{-0.25 in}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8.5 in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\parindent}{0.0in}
\setlength{\parskip}{7pt plus 1pt}

\usepackage{url}

\sloppy

\begin{document}

\title{Wallingford and Rosette}
\author{Alan Borning}
\date{\today}

\maketitle

\section{Introduction}

The overall goal of this project is to investigate constraint reactive
programming languages --- that is, (mostly) declarative languages that
integrate constraints with reactive programming, in a way that cleanly
accommodates state and change.  To get started, I've been writing an
initial version of the language, called Wallingford, that includes support
for writing interactive graphical applications in Rosette, but not yet
any support for reactive programming.  This draws on experience in
developing Babelsberg, a family of object constraint languages that
also supports declaring constraints in an object-oriented language and
is targeted at interactive graphical applications (as well as others).

This note is a snapshot of the work to date.  Section
\ref{sec:babelsberg} describes some relevant features of Babelsberg,
while Section \ref{sec:rosette} compares these features with what is
available in Rosette.  Then, Section \ref{sec:core-wallingford}
describes the core of the current Wallingford design, while Section
\ref{sec:closer-to-babelsberg} describes a variant that attempts to
move Wallingford as close to Babelsberg as possible.

Babelsberg and Rosette take rather different approaches to primitive
types and simple user-defined structures such as points.  In
Babelsberg, these are immutable, and can be passed freely.  Weak stay
constraints cause variables that hold these values to keep their
current values as time advances, unless there is some stronger
constraint that forces them to change.  In contrast, in Rosette
symbolic constants are used to hold numbers and booleans and other
primitive types that can be constrained.  These can also be used in
user-defined structures.  As time advances, the current constraints on
these symbolic constants can be removed, but the shell structure
persists.  More on this difference at the end of Section \ref{sec:rosette}.

The code described in this note is in the repository
\verb|https://github.com/cdglabs/wallingford.git|; this note is in
the \verb|docs| subdirectory.

\section{Babelsberg}
\label{sec:babelsberg}

Babelsberg is a family of object constraint languages that allows
constraints to be integrated with an existing object-oriented
language.  The most useful Babelsberg reference with respect to this
memo is the OOPSLA 2015 paper \cite{felgentreff-oopsla-2015}; other
papers and tech reports are
\cite{FelgentreffJOT14,felgentreff-ecoop-2014,
  felgentreff-step-by-step-tr}.  Current implementations are
Babelsberg/Ruby, Babelsberg/Javascript, and Babelsberg/Squeak (Squeak
being a Smalltalk dialect).

Babelsberg enables the programmer to write constraints on objects that
include OO constructs such as message sends and that respect object
encapsulation.  For example, this constraint specifies that the center
of a rectangle \verb|r| remain at a fixed position as its other
attributes are updated.\footnote{The examples in this section are
  written in pseudo-code, following the examples in the tech report
  \cite{felgentreff-step-by-step-tr}.}

\begin{verbatim}
always r.center() = Point(10,20)
\end{verbatim}

It doesn't matter whether \verb|center| is stored as a field of the
rectangle or computed via a method; in either case, the Babelsberg
implementation will evaluate the constraint expression in constraint
construction mode to rewrite it into a set of primitive constraints
that can then be turned over to the solver.

A key aspect of Babelsberg is the handling of state, assignment, and
object identity.  (The OOPSLA 2015 paper
\cite{felgentreff-oopsla-2015} and a longer tech report
\cite{felgentreff-step-by-step-tr} describe our current scheme for
this.)  Babelsberg makes a distinction between instances of primitive
types and of value classes, for which object identity is not
significant and that aren't stored on the heap, and instances of
classes for which identity is significant and that are stored on the
heap.  First let's look at a few examples using primitive types and
value classes.

\begin{verbatim}
x := 3;
y := x;
always y=10;
\end{verbatim}

At the end of this fragment we have \verb|x=3| and \verb|y=10|.
\verb|x| and \verb|y| hold instances of a primitive type (integers in
this case), and so even though we assign \verb|x| to \verb|y|, they
are not aliased, and the always constraint only affects \verb|y|.  In
addition to persistent constraints (written using \verb|always|
above), there are implicit soft stay constraints to give stability in
the absence of other stronger constraints --- so after the initial
assignment to \verb|x|, there is a low-priority stay constraint on it
so that it retains that value.  There is also a low-priority stay
constraint on \verb|y| after the assignment \verb|y:=x|, but this stay
is overridden by the required constraint \verb|y=10|.

Here's a similar example, using instances of a value class \verb|point|.
\begin{verbatim}
p := point(3,4);
q := p;
always q.x=10 & q.y=20;
\end{verbatim}
At the end we have \verb|p=point(3,4)| and \verb|q=point(10,20)| ---
no aliasing relation is set up between \verb|p| and \verb|q| since
they contain value class instances.  As before, low-priority stay
constraints cause \verb|p| and \verb|q| to retain their values in the
absence of stronger constraints.

On the other hand, if we do something similar with mutable points that
do have object identity, we get a different result:
\begin{verbatim}
p := new mutable_point(3,4);
q := p;
always q.x=10 & q.y=20;
\end{verbatim}
After the second statement, \verb|p| and  \verb|q| are aliased, and so
the always constraint on \verb|q| also causes \verb|p| to change
(since in fact they are the same object).

We can also have explicit identity constraints:
\begin{verbatim}
p := new mutable_point(3,4);
q := p;
always p==q;  /* object identity */
q := new mutable_point(10,20);
\end{verbatim}

After the last assignment, \verb|p| and \verb|q| both reference the
newly-created point (10,20).

Semantically, all the constraints are solved after each statement.
Babelsberg uses various techniques to enable reasonable performance on
interactive problems, such as ``edit'' constraints that can take
advantage of incremental solvers, and keeping track of dependencies
for partially-evaluated code.  For now, however, we will mostly set
efficiency considerations aside.

The OOPSLA paper discusses the issue of taming the power of the
constraint solver so that it can't (for example) on its own create new
objects with object identity to satisfy constraints, add fields or
methods to objects, or the like.  For example, suppose we add an
additional constraint to the mutable points example:
\begin{verbatim}
p := new mutable_point(3,4);
q := p;
always q.x=10 & q.y=20;
always p.x=0 & p.y=0;
\end{verbatim}
These constraints are unsatisfiable --- the system won't create a new
mutable object for \verb|p|, even though doing so would allow the
constraints to be satisfied.

However, creating new instances of value classes is allowed.  Here's
the same example with value classes for points:
\begin{verbatim}
p := point(3,4);
q := p;
always q.x=10 & q.y=20;
always p.x=0 & p.y=0;
\end{verbatim}

At the end of this program, we have \verb|p=point(0,0)| and
\verb|q=point(10,20)|.

Please see the OOPSLA paper for more examples, and the longer
technical report for a series of examples for different Babelsberg
instantiations, first just for numbers, then for immutable records,
then for mutable records with object identity, and finally
full-fledged objects.

\section{Rosette}
\label{sec:rosette}

Rosette is a solver-aided language that extends Racket with
\emph{symbolic data types} and solver operations
\cite{torlak-onward-2013,torlak-pldi-2014}.  For example, the
following Rosette statements declare two symbolic variables and
constraints on them, and then find a solution that satisfies these
constraints:
\begin{verbatim}
  (define-symbolic x y number?)
  (assert (equal? y (+ x 2)))
  (assert (equal? x 10))
  (solve #t)
\end{verbatim}

The previous example of a constraint on the center of a rectangle has
the following analog in Rosette:

\begin{verbatim}
(assert (equal? (rect-center r) (point 10 20)))
\end{verbatim}

As with Babelsberg, the expression is evaluated in the host language
(Racket in this case), and \verb|(rect-center r)| will be partially
evaluated away prior to reaching constructs known to Rosette.  The
interpretation of the assertion can also change depending on the
binding of (for example) \verb|rect_center|.  However, the
\verb|assert| statement just asserts the constraint at the time it is
evaluated, unlike \verb|always| in Babelsberg that re-asserts the
constraint at each time step.

Such persistent constraints declared using \verb|always|, as well as
the low-priority stay constraints, are not supported primitively in
Rosette, but it is straightforward to add them in a DSL on top of
Rosette, as described in the next section.

Object identity is handled in a similar manner in the two systems.  In
both systems, object identity is not relevant for primitive types, nor
for transparent immutable structures (in Rosette) or instances of
value classes (in Babelsberg) --- in fact, Rosette redefines the
behavior of Racket's \verb|eq?| predicate for transparent immutable
datatypes so that object identity is not significant.  Object identity
is significant for opaque or mutable structures (in Rosette) and for
instances of mutable records or ordinary classes (in Babelsberg).  The
only real difference, I believe, is that Babelsberg allows explicit
constraints on object identity.

A significant difference concerns how variables, state, and assignment
are handled.  First, let's consider primitive types.  In Babelsberg, a
variable might hold an instance of a primitive type.  The programmer
can put constraints on the variable that must be satisfied for
required constraints, or that should be satisfied if possible for soft
constraints.  Weak stay constraints cause variables to retain their
values in the absence of an explicit assignment or stronger
constraints.  Concrete values in Rosette are similar; but to make use
of constraints, programmers declare symbolic constants.  They can then
assert constraints on these symbolic constants and ask the solver for
a satisfying solution.  Programmers can also make aliases for these
symbolic constants, or pass them to procedures and in those procedures
put assertions on the symbolic constants.  In contrast, in Babelsberg,
aliasing doesn't apply to instances of primitive types.

For example, consider the following Rosette program.

\begin{verbatim}
(define-symbolic x y number?)
(set! y x)   ; probably a bad idea!  see below
(solve (assert (equal? x 3))
\end{verbatim}

In the current solution, \verb|x| will have the value 3, as one would
expect --- but so will \verb|y|, since \verb|x| and \verb|y| are in
effect aliased, even though they are numbers.

Instances of user-defined value classes in Babelsberg are also
immutable and can be passed freely to procedures or methods without
the possibility of assigning to them or constraining them in the
procedure.  In Rosette, transparent immutable structures can hold
symbolic constants, and so the same considerations apply to them as to
symbolic constants themselves.

A capsule summary of the differences for primitives and other types
without object identity is as follows.  In Babelsberg, such values are
immutable --- constraints on variables and stay constraints are used
to update the values as time progresses.  In Rosette, symbolic
constants, and immutable transparent structures that contain them,
form a kind of shell.  The programmer can clear all the assertions on
them, or even make assertions that apply only within a particular call
to \verb|solve|; but the structure persists independent of these
assertions.  A symbolic value (either of a primitive type or a struct)
may have a binding in the current solution, but in another solution
may have a different binding.  This concept of symbolic values and
different bindings does not exist in Babelsberg.  On the one hand, the
Rosette approach bypasses all the issues with taming the power of the
constraint solver that we struggled with in Babelsberg, since the
solver just works on the leaves (symbolic numbers, booleans, etc), and
not on user-defined structures.  On the other hand, Rosette programs
have the issue of being able to constrain these shell structures (both
for primitives and for user-defined structs), whereas in Babelsberg a
number or an instance of a value class can be passed around freely
without concern about another procedure side-effecting it.

Curiously, the situtation with ordinary objects in Babelsberg, and
mutable or opaque structs in Rosette, is much closer.  In both
systems, the solver can't make new objects or spontaneously change the
object to which a variable refers to satisfy constraints.

\section{The Core Wallingford System}
\label{sec:core-wallingford}

The core Wallingford system includes a small set of functions and macros to
extend Rosette for use in constructing interactive graphical applications.
The code for this is in the \verb|wallingford/core| subdirectory of the git
repository.

Based on experience with ThingLab, Kaleidoscope, and Babelsberg, I think
the key features needed for this core system are as follows:

\begin{enumerate}
\item\label{objects} the ability to build objects with persistent
  constraints, such as constrained geometric objects, GUI widgets with
  constraints, or simulation elements

\item\label{frame-axioms} a facility for implementing frame axioms
  (specifying that things remain the same unless there is some reason
  they should change)
\end{enumerate}

Regarding Feature \ref{objects}, I've described this in terms of
objects; and indeed objects, classes, and subclasses provide a natural
mechanism for this.  However, Racket structs, along with functions,
will also do.

Regarding Feature \ref{frame-axioms}, hard and soft constraints
\cite{borning-lisp-symbolic-computation-1992} have proven expressive
and also useful as a basis for efficient incremental solvers,
e.g.\ DeltaBlue and Cassowary.  Adding a facility for declaring
relative priorities (``the priority for the stay on object X should be
higher than that for object Y'') could be useful.  Such relative
priorities could then be used to determine absolute priorities that
support all of the relative relations (or to determine that the
relative relations are incompatible); this in turn would allow the
re-use of the existing algorithms and theory for hard and soft
constraints.

The following functions and macros allow the programmer to declare
hard and soft persistent constraints, as well as ``stay'' constraints
that instruct the system to leave values where they are unless some
stronger constraint forces them to change.

\begin{description}

\item[{\tt always}] This function takes a constraint and an optional
  priority, and adds that constraint to the set of constraints that will be
  enforced thereafter.  The priority defaults to {\tt required}.  For
  example, here is a constraint to keep a midpoint halfway between the two
  endpoints of a line:

\begin{verbatim}
(always (equal? midpoint 
                (point-times (point-plus (line-end1 line1) (line-end2 line1)) 0.5)))
\end{verbatim}

The bindings for the variables used in the ``always'' function are
determined at the time the function is called --- they don't track the
variables if they are re-assigned to something else.

\item[{\tt always*}] This macro functions almost the same as
  \verb|always|, except that the expression \emph{is} re-evaluated at
  each step, so that the constraint applies to the new bindings of
  variables if they are re-assigned.  This doesn't usually arise; an
  example where it does is in a set of objects representing resistors,
  batteries, and other electrical circuit components.  If we want to
  represent a Kirchhoff's Law constraint that the sum of the currents
  into a node be 0, and have that constraint dynamically update as we
  connect or remove components, we want to use \verb|always*|.  To
  compare these, see the files
  \verb|applications/electrical-things.rkt| (uses \verb|always|) and
  \verb|applications/electrical-things-dynamic.rkt| (uses
  \verb|always*|).  It's not clear we need both of these --- perhaps
  we should just use the \verb|always*| semantics, backed with a more
  efficient implementation (see Section \ref{sec:next-steps}) --- but
  they are both in there for now as we explore the language.

\item[{\tt stay}] This function takes an expression and a priority,
  and adds a stay constraint to the system that the value of the
  expression stay the same each iteration.  The default priority is
  {\tt lowest}, meaning that if more or less any other constraint
  comes along that wants the value to be something else it will
  change, and otherwise remain the same.  For example, these calls
  tell the system that the two endpoints of a line should not move
  unless necessary (with low but not the lowest priority):

  \begin{verbatim}
  (stay (line-end1 line1) #:priority low)
  (stay (line-end2 line1) #:priority low)
  \end{verbatim}

\item[{\tt wally-clear}]  This function cleans out all of the constraints
  and stays.

\item[{\tt wally-solve}] This function is basically equivalent to
  Rosette's {\tt solve} macro, augmented with features to support
  Wallingford.  It find a solution to the global assertion store plus
  all constraints declared using \verb|always| and \verb|stay|.
  Required constraints must be satisfied, while soft constraints
  should be satisfied if possible, respecting their relative
  priorities.  Stay constraints are considered relative to the current
  state of the system, i.e., to the \verb|(current-solution)| object
  at the start of solving.  After finding a solution, clear the global
  assertion store.  When we return from calling \verb|wally-solve|,
  the global \verb|(current-solution)| object holds a solution.  As
  usual in Rosette, \verb|(evaluate v)| can then be used to evaluate
  \verb|v| with respect to the current solution.

\end{description}

The \verb|wallingford/applications| directory has a few examples of using
these functions and macros.  \verb|geothings.rkt| contains some definitions
of simple geometric objects with constraints. \verb|quadrilateral.rkt| uses
these to define an interactive demo that lets the user drag the endpoints
of lines that form a quadrilateral with an embedded parallelogram.
\verb|electrical-things.rkt| and \verb|electrical-things-dynamic.rkt| have
two styles of defining electrical circuit components; the unit tests in the
\verb|wallingford/tests| directory wire up some circuits using them.

These examples use structs rather than objects for things like points,
lines, and resistors.  A useful design pattern for these has been to
define a function that creates a new point, line, resistor, or
whatever with Rosette symbolic variables at the leaves, as well as any
needed constraints.  For example, here are structs and creation
functions for some geometric objects:

\begin{verbatim}
(struct point (x y) #:transparent)
(struct line (end1 end2) #:transparent)
(struct midpointline (line midpoint) #:transparent)

(define (make-point)
  (define-symbolic* x y number?)
  (point x y))

(define (make-line)
  (line (make-point) (make-point)))

(define (make-midpointline)
  (define line1 (make-line))
  (define midpoint (make-point))
  (always (equal? midpoint
                  (point-times (point-plus (line-end1 line1) (line-end2 line1)) 0.5)))
  (midpointline line1 midpoint))
\end{verbatim}

There are analogous creation functions in the electrical circuit files
for resistors, batteries, circuit nodes, and so forth.

\section{How Close to Babelsberg Can We Make This?}
\label{sec:closer-to-babelsberg}

The core Wallingford constructs described in the previous section
allow the programmer to build interactive graphical applications that
include persistent constraints and stays.  However, it doesn't have
direct support for compound datatypes or objects, identity
constraints, and other features of Babelsberg.  This leads to the
question: how close to Babelsberg can we come with a language built on
Rosette?  The Wallingford variant described in this section attempts
to answer this by adding functions and macros to get closer to
Babelsberg.  At this point I view this as an interesting experiment,
but it's not clear that it is on the long-term path toward a
constraint reactive programming language.  This experiment is in a
different subdirectory of the wallingford repository, namely
\verb|wallingford/babelsberg|.

This variant includes all of the functions and macros described in
Section \ref{sec:core-wallingford}, some significantly altered.  In
particular \verb|always| can be used to define identity constraints as
well as ordinary value constraints.  For example, this constraint
connects two resistors by making the nodes at their \verb|node1| ends
be identical.

\begin{verbatim}
(always (eq? (resistor-node1 r1) (resistor-node1 r2)))
\end{verbatim}

There are also the following additional functions and macros.

\begin{description}

\item[{\tt symbolic-struct}] Ordinary Racket contains a \verb|struct| macro
  to define simple structs; this is lifted in Rosette.  The
  \verb|symbolic-struct| macro lets the programmer declare symbolic
  structs, such as points or lines, so that the programmer-defined creation
  functions discussed in Section \ref{sec:core-wallingford}, such as
  \verb|make-point| and \verb|make-line|, are defined automatically.
  For example, here are the definitions for symbolic points and lines:
  \begin{verbatim}
  (symbolic-struct point ([x number?] [y number?]))
  (symbolic-struct line ([end1 point?] [end2 point?]))
  \end{verbatim}
These symbolic structs are intended to fill an analogous role to that
filled by value classes in Babelsberg.  Right now the implementation
doesn't include a way to also declare constraints at the time the
struct is created, but this would be straightforward to add (and
should be added if we were going to move forward with this part of the
experiment). 

\item[{\tt wally-define-symbolic}, {\tt wally-define-symbolic*}] These
  macros function identically to the Rosette \verb|define-symbolic| and
  \verb|define-symbolic*| macros for numbers and booleans, but also allow
  declaring symbolic constants that are instances of symbolic structs,
  e.g., \verb|(wally-define-symbolic p point?)|

\item[{\tt wally-set!}] This macro is intended to replace
  \verb|set!|~to account for symbolic values and identity constraints
  when assigning to a variable.  (To simplify things, for now it has a
  different name.)  Given a statement \verb|(wally-set! var expr)|, if
  \verb|var| is an instance of a value class, we assert that
  \verb|var| is equal to the value of \verb|expr| in the current
  solution and solve using \verb|wally-solve|.  Otherwise we do a
  conventional assignment of \verb|var| to the result of evaluating
  \verb|expr| in the current solution, satisfy any explicit identity
  constraints by setting other variables as needed, and then solve
  using \verb|wally-solve|.  This essentially implements the two-phase
  constraint solving used in Babelsberg (first solve for identity
  constraints, then value constraints).

\end{description}

There are a few conventions that should be followed to make this version of
the language work.  Any variables that will hold primitives or transparent
immutable structs, i.e., analogs of primitive or value class types from
Babelsberg, should be declared using \verb|wally-define-symbolic| or
\verb|wally-define-symbolic*|, not with \verb|define|.  (A consequence of
this is that we can't dynamically change the types of constrainable
variables.)  Assignments to such variables should be done using
\verb|wally-set!|~rather than \verb|set!|.  Finally, if such a symbolic
variable is passed as a parameter to a procedure, the procedure should not
put constraints on it.  (As in Racket and Rosette, parameters are passed by
value, with pointer semantics for objects with UIDs\@.)  These conventions
avoid the sorts of aliasing issues mentioned in Section \ref{sec:rosette}.

These restrictions are just for primitives or transparent immutable
structs; variables that hold values for which identity is significant are
declared in the usual way (using \verb|define|), and can have identity
constraints on them.  I believe that with these conventions the Babelsberg
theorems presented in \cite{felgentreff-oopsla-2015} hold for the
Wallingford variant as well.  There are a set of tests in
\verb|wallingford/babelsberg| that demonstrate these conventions and the
behavior of the language, including analogs of the programs in Section
\ref{sec:babelsberg}.

\section{Next Steps}
\label{sec:next-steps}

The core Wallingford system described in Section
\ref{sec:core-wallingford} seems like a promising basis for future
work.  At this point, as noted previously, I would characterize the
experiment described in Section \ref{sec:babelsberg} (an attempt at a
language implemented in Rosette that is as close as possible to
Babelsberg), as interesting but probably not itself the basis for the
eventual system --- the underlying model for primitives and value
classes seems too different to make this a smooth integration.
However, perhaps some of the ideas, such as explicit identity
constraints, will prove useful still in the future.

The next steps are to begin designing a language that integrates
reactive programming with the core Wallingford language.  This design
should be driven by a set of examples.  My current list is a set of
standard GUI elements (buttons, sliders, draggable points on objects
with constraints), as well as simple animations and physical
simulations, e.g., a bouncing ball.  (Should we have more novel sorts
of examples?  One suggestion is expressing and formalizing multi-touch
interactions using constraints.)

After that there are several interesting directions, including
supporting end-user programming, probably in a visual or mixed
programming environment, and inferring constraints from examples.
Alan Kay has also been pushing the group to use the Parable of the
Polygons (\url{http://ncase.me/polygons/}) as a driving example for
end-user programming.

\section{Implications for Rosette}

A short-term need is adding reals or floats in Rosette, and
exposing the minimize and maximize Z3 operators in Rosette to support
minimizing the error in satisfying soft constraints.

There may be a need to support certain operations more efficiently,
but this should wait for more experience.

\bibliographystyle{plain}
\bibliography{constraints}

\end{document}
